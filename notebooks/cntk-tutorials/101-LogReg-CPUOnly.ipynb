{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful notes before starting\n",
    "\n",
    "* If you can't run F# jupyter notebooks locally go to [IfSharp Project](https://github.com/fsprojects/IfSharp) for binaries and installation instructions.\n",
    "\n",
    "* [F# for jupyter Feature Notebook](https://github.com/fsprojects/IfSharp/blob/master/FSharp_Jupyter_Notebooks.ipynb)\n",
    "\n",
    "* [F# Cheetsheet](https://dungpa.github.io/fsharp-cheatsheet/)\n",
    "\n",
    "Be aware that if you are viewing this directly on [**GitHub**](https://github.com/SpaceAntelope/IfCntk/blob/master/notebooks/cntk-tutorials/101-LogReg-CPUOnly.ipynb) you are missing features such as F# specific syntax highlighting and ligatures, as well as some other inline html styling in markdown cells. Perhaps most importantly, you will not be able to see any XPlot visualizations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the workspace for CNTK in jupyter\n",
    "\n",
    "If referencing CNTK fails, make sure you have followed the instructions in my [Preparing Workspace.ipynb](https://github.com/SpaceAntelope/IfCntk/tree/master/notebooks/cntk-tutorials/Preparing%20workspace.ipynb) notebook. The current notebook assumes that all necessary CNTK nuget DLLs have been copied to a folder named **bin** in the same path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Congratulations, you are using CNTK for: CPU\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"netstandard\"\n",
    "#r @\"bin\\Cntk.Core.Managed-2.6.dll\"\n",
    "#load @\".paket\\load\\main.group.fsx\"\n",
    "\n",
    "open System\n",
    "open System.IO\n",
    "\n",
    "Environment.GetEnvironmentVariable(\"PATH\")\n",
    "|> fun path -> sprintf \"%s%c%s\" path (Path.PathSeparator) (Path.GetFullPath(\"bin\"))\n",
    "|> fun path -> Environment.SetEnvironmentVariable(\"PATH\", path)\n",
    "\n",
    "open CNTK\n",
    "DeviceDescriptor.UseDefaultDevice().Type\n",
    "|> printfn \"Congratulations, you are using CNTK for: %A\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNTK 101: Logistic Regression and ML Primer\n",
    "\n",
    "This notebook is primarily an F# port of [CNTK_101_LogisticRegression](https://github.com/Microsoft/CNTK/blob/master/Tutorials/CNTK_101_LogisticRegression.ipynb). I have kept some of the original code comments to make it easier to follow along with the python notebook, but I am skipping the detailed explanations of machine learning concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "This being the first notebook, helper functions that emulate ipython functionality more precisely will be presented in full. As the series progresses, any such functions declared in previous notebooks will be referenced from a **NbHelper** namespace without further comment.\n",
    "\n",
    "To get things started, here's a small function to inline images from urls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// Simple wrapper to show inline images from url \n",
    "/// with customizable width\n",
    "/// <remarks> Notebook Helper Function </remarks>\n",
    "let ImageUrl url width =\n",
    "    sprintf \"<img src=\\\"%s\\\" style=\\\"width: %dpx; height: auto\\\" alt=\\\"Could not load image, make sure url is correct\\\">\" url width\n",
    "    |> Util.Html\n",
    "    |> Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "// Figure 1\n",
    "ImageUrl \"https://www.cntk.ai/jup/cancer_data_plot.jpg\" 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Figure 2\n",
    "ImageUrl \"https://www.cntk.ai/jup/cancer_classify_plot.jpg\" 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Figure 3\n",
    "ImageUrl \"https://www.cntk.ai/jup/logistic_neuron.jpg\" 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Let's hear it for our first learning parameters!</h3> <p>I will be declaring any global parameters in the same sequence as the original python notebook, since this is meant as a companion piece after all, and the eventual fsx script for this notebook will have them all gathered together in one place.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let featureCount = 2\n",
    "let labelCount = 2\n",
    "let sampleCount = 32\n",
    "let device = DeviceDescriptor.CPUDevice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should take special notice of the device descriptor parameter that defines if a CNTK.Function runs on CPU or a GPU, as pops up as a parameter in a lot of CNTK functions and it's pretty much an open topic how to best treat it in F#. Other than to declare it globally just call it whenever as I have done here, that is.\n",
    "\n",
    "If you are interested in exploring the topic further be sure to check Mathias Brandenwinder's discussion of the issue and proposed functional solution [here](http://brandewinder.com/2018/01/14/CNTK-etudes-sequential-model/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "Here's our first attempt at doing **numpy** with **MathNet.Numerics**. The aim is a function that will produce distinct (but not too distinct!) clusters of random points to be used as mock datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "open MathNet.Numerics.Distributions;\n",
    "\n",
    "let seed = 42\n",
    "let rand = System.Random(seed)\n",
    "let nrand = Normal(0.,1.,rand)\n",
    "let randInt max = seq { while true do yield rand.Next() % max }\n",
    "let randn = Normal.Samples(rand, 0.0, 1.0)\n",
    "let oneHotEncoding classCount classType =\n",
    "    Array.init classCount (fun i -> if i = classType then 1.0f else 0.0f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open MathNet.Numerics.LinearAlgebra\n",
    "\n",
    "let generateRandomDataSample sampleCount featureCount labelCount = \n",
    "    let Y = Array.init sampleCount\n",
    "                (fun _ -> float32 (rand.Next() % labelCount) )\n",
    "    let X = DenseMatrix.init sampleCount featureCount \n",
    "                (fun row col -> float32 (nrand.Sample() + 3.) * (Y.[row]+1.f) )                 \n",
    "    let oneHotLabel = \n",
    "        Y\n",
    "        |> Array.map(int>>(oneHotEncoding labelCount))\n",
    "        |> DenseMatrix.ofRowArrays\n",
    "\n",
    "    X, oneHotLabel\n",
    "    \n",
    "let x,y = generateRandomDataSample 32 2 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">You should avoid using a global variable named <b>X</b> for the feature vector, appropriate though it may look, as it apparently clashes with an XPlot global.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "\n",
    "In order to properly wire **FSharp.Charting** and **XPlot.Plotly** to display in the notebook you need to either \n",
    "* Run paket.exe in the same folder as ifsharp.exe and add them from there, <u>and then delete the .paket/load folder</u> because otherwise it will supersede any calls to your own notebook's generated load scripts, or \n",
    "* Modify the #r calls in FSharp.Charting.fsx and XPlot.Plotly.fsx to point to where the relevant DLLs actually are.\n",
    "\n",
    "This will by no means be a deep dive into XPlot's API, rather more of a gentle nudge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Setup display support\n",
    "#load \"XPlot.Plotly.fsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open XPlot.Plotly\n",
    "\n",
    "let colors = \n",
    "    [for label in y.Column(0) do \n",
    "        yield if label = 0.f then \"Red\" else \"Blue\"]\n",
    "    \n",
    "Scatter(x = x.[*,0], y = x.[*,1], \n",
    "        mode = \"markers\", \n",
    "        marker = Marker(size=10, color=colors))\n",
    "|> Chart.Plot\n",
    "|> Chart.WithLayout (\n",
    "        Layout( xaxis=Xaxis(title=\"Tumor size (in cm)\"), \n",
    "                yaxis=Yaxis(title=\"Age (scaled)\")))\n",
    "|> Chart.WithHeight 400\n",
    "|> Chart.WithWidth 600        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Figure 4\n",
    "ImageUrl \"https://www.cntk.ai/jup/logistic_neuron2.jpg\" 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *IfSharp* global for parsing LaTeX notation seems to work fantastically, except for **\\cdot** which I put there with Alt+0183:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"z=\\sum_{i=1}^n w_i \\\\times x_i+b= \\\\textbf{w Â· x}+b\" |> Util.Math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here comes the CNTK managed API!\n",
    "\n",
    "These will be the first of numerous small helper functions to make CNTK's .NET API more easily useable from F#, owing to a pair of distinct characteristics: \n",
    "<ol type='i'>\n",
    "    <li> It's way more low level that the Python API we are aiming to match.</li>\n",
    "    <li> It plays fast and loose with implicit type conversions in a way that F# is very uncomfortable with allowing.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// In C# a function parameter of type NDShape apparently \n",
    "/// can accept a simple int array and cast away implicitly.\n",
    "/// \n",
    "/// Not so in F#.\n",
    "/// <remarks>CNTK Helper function</remarks>\n",
    "let inline shape (dims:int seq) : NDShape = NDShape.CreateNDShape dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><span class=\"glyphicon glyphicon-info-sign\"></span><span>Hyperparameters!</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let dataType = CNTK.DataType.Float //type fsDataType = float32 // possible to be used for casting later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"_alert _alert-info\"><p>If you are coming at this from a C# background, this is a good time to note that The F# <b>float</b> type corresponds to <b>System.Double</b>, and requires the CNTK model to be initialised with <b>CNTK.DataType.Double</b>.</p><p>Conversely, to use <b>CNTK.DataType.Float</b> such as the case is here, your numbers need to be typed as either <b>float32</b> or <b>single</b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Since the original Python example is murky on initialization specifics I've used 1.0 and 0.0 as init values for weights and bias respectively, just as they appear in this  <a href=\"https://github.com/Microsoft/CNTK/blob/master/Examples/TrainingCSharp/Common/LogisticRegression.cs\" target=\"_blank\">CNTK C# sample</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let featureVariable = Variable.InputVariable(shape [|featureCount|], dataType, \"Features\")\n",
    "let initialization = CNTKLib.GlorotUniformInitializer(1.0)\n",
    "let index = System.Collections.Generic.Dictionary<string, CNTK.Parameter>()\n",
    "\n",
    "let linearLayer (inputVar : Variable) outputDim =\n",
    "    let inputDim = inputVar.Shape.[0] \n",
    "    let weightParam = new Parameter(shape [inputDim; outputDim], dataType, initialization, device, \"Weights\")\n",
    "    let biasParam = new Parameter(shape [outputDim], dataType, 0.0, device, \"Bias\")    \n",
    "    \n",
    "    index.Add(\"Weights\", weightParam)\n",
    "    index.Add(\"Bias\", biasParam)\n",
    "    \n",
    "    // training works for w * i and not for i * w as in the python example \n",
    "    let dotProduct =  CNTKLib.Times(weightParam, inputVar, \"Weighted input\")\n",
    "    let layer = CNTKLib.Plus(new Variable(dotProduct), biasParam, \"Layer\")\n",
    "    \n",
    "    layer\n",
    "\n",
    "let z = linearLayer featureVariable labelCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><p>As noted in the code comments, the order of vector multiplication is inverted relative to how they appear in the corresponding function in the CNTK Python API.</p><p>I doubt you can escape this mistake the first time if you're learning the .NET API by following along the Python tutorial.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\\\\textbf{p}=softmax(z)\" |> Util.Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"H(p)=-\\sum_{j=1}^{|y|}y_j log(p_j)\" |> Util.Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let labelVariable = Variable.InputVariable(shape [labelCount], dataType, \"output\")\n",
    "let loss = CNTKLib.CrossEntropyWithSoftmax(new Variable(z), labelVariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><span class=\"glyphicon glyphicon-info-sign\"></span><span>Hyperparameters!</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let evalError = CNTKLib.ClassificationError(new Variable(z), labelVariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although you can use a variety of functions for error evaluation and loss, the overall behavior of the network might change enough that I hesitate to mark them as simple hyperparameters to be fine tuned; not piping the network output through softmax for instance takes a lot out of our ability to interpret the output probabilistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// A sequence of Parameter objects needs to be converted \n",
    "/// to type ParameterVector in order to be passed to CNTK functions.\n",
    "/// <remarks> CNTK Helper function </remarks>\n",
    "let ParVec (pars:Parameter seq) = \n",
    "    let vector = new ParameterVector()\n",
    "    pars |> Seq.iter (vector.Add)\n",
    "    vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// <remarks> CNTK Helper function </remarks>\n",
    "let inline normalizeByMax(max:'T) (source : 'T seq) =\n",
    "    source |> Seq.map ((fun n -> float n/ float max)>>float32)\n",
    "\n",
    "/// Convert MathNet 2d matrix to batch in one go, while accounting for \n",
    "/// original dimensionality and numeric type.\n",
    "/// <remarks> CNTK Helper function </remarks>\n",
    "let matrixToBatch(m : Matrix<float32>) =    \n",
    "    CNTK.Value.CreateBatch(shape [m.Rank()], Matrix.toSeq m, device)\n",
    "    \n",
    "let matrixToSingleToBatch(m : Matrix<float>) =    \n",
    "    CNTK.Value.CreateBatch(shape [m.Rank()], Matrix.toSeq <| m.ToSingle(), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I see what you did there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// Define a utility function to compute the moving average.\n",
    "/// A more efficient implementation is possible with np.cumsum() function\n",
    "/// <remarks> Helper Function. \n",
    "/// *Summary from comments in python notebook</remarks>\n",
    "let movingAverage (array : float seq) windowLength = \n",
    "    if (array |> Seq.length) >= windowLength\n",
    "    then array\n",
    "         |> Seq.windowed windowLength \n",
    "         |> Seq.map (Seq.average)        \n",
    "    else seq [array |> Seq.average]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><span class=\"glyphicon glyphicon-info-sign\"></span><span>Hyperparameters!</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Instantiate the trainer object to drive the model training\n",
    "let learningRate = 0.01\n",
    "let lrSchedule = new CNTK.TrainingParameterScheduleDouble(learningRate, uint32 CNTK.DataUnit.Minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = CNTKLib.SGDLearner(z.Parameters() |> ParVec, lrSchedule)\n",
    "let trainer = CNTK.Trainer.CreateTrainer(z, loss, evalError, ResizeArray<CNTK.Learner>([learner]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training information logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Define a utility that prints the training progress\n",
    "let printTrainingProgress (trainer: CNTK.Trainer) minibatch frequency verbose = \n",
    "    if minibatch % frequency = 0 \n",
    "    then     \n",
    "        let mbla = trainer.PreviousMinibatchLossAverage()\n",
    "        let mbea = trainer.PreviousMinibatchEvaluationAverage()\n",
    "        \n",
    "        if verbose then \n",
    "            printfn \"Minibatch: %d, Loss: %.4f, Error: %.2f\" minibatch mbla mbea\n",
    "    \n",
    "        Some (minibatch, mbla, mbea)\n",
    "    else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the trainer\n",
    "\n",
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let minibatchSize = 25\n",
    "let numSamplesToTrain = 20000\n",
    "let numMinibatchesToTrain = int (numSamplesToTrain/minibatchSize)\n",
    "let progressOutputFreq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type TrainReport = { \n",
    "    BatchSize: ResizeArray<int> \n",
    "    Loss: ResizeArray<float>\n",
    "    Error: ResizeArray<float> } \n",
    "\n",
    "let plotdata = { \n",
    "    BatchSize = ResizeArray<int>()\n",
    "    Loss = ResizeArray<float>()\n",
    "    Error = ResizeArray<float>()\n",
    "}\n",
    "\n",
    "for i in [0..numMinibatchesToTrain] do\n",
    "    let x,y = generateRandomDataSample minibatchSize featureCount labelCount\n",
    "    let features,labels = matrixToBatch x, matrixToBatch y\n",
    "    \n",
    "    // Assign the minibatch data to the input variables and train the model on the minibatch\n",
    "    let trainingBatch = [(featureVariable, features);(labelVariable, labels)] |> dict\n",
    "    let status = trainer.TrainMinibatch(trainingBatch, true, device)\n",
    "    \n",
    "    // log training data\n",
    "    match (printTrainingProgress trainer i progressOutputFreq true) with\n",
    "    | Some (i,loss,eval) ->         \n",
    "        plotdata.BatchSize.Add <| i\n",
    "        plotdata.Loss.Add <| loss\n",
    "        plotdata.Error.Add <| eval\n",
    "    | None -> ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let lossMax = plotdata.Loss |> Seq.max\n",
    "let dash = Line(dash=\"dash\")\n",
    "\n",
    "[   Scatter(name=\"Loss (scaled)\", line=dash,\n",
    "            x = plotdata.BatchSize, \n",
    "            y = (plotdata.Loss |> normalizeByMax lossMax))\n",
    "    Scatter(name=\"Error\",\n",
    "            x = plotdata.BatchSize, \n",
    "            y = plotdata.Error, line=dash)] \n",
    "|> Chart.Plot\n",
    "|> Chart.WithLayout (Layout(title=\"Minibatch run\", \n",
    "                            xaxis=Xaxis(title=\"Minibatch number\"), \n",
    "                            yaxis=Yaxis(title=\"Cost\")))\n",
    "|> Chart.WithHeight 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Compute the moving average loss to smooth out the noise in SGD\n",
    "let avgLoss = movingAverage (plotdata.Loss) 10 \n",
    "let avgError = movingAverage (plotdata.Error) 10\n",
    "let maxAvgLoss = avgLoss |> Seq.max\n",
    "\n",
    "[   Scatter(name=\"Average Loss (scaled)\", line=dash,\n",
    "            x = plotdata.BatchSize, y = (avgLoss |> normalizeByMax maxAvgLoss))\n",
    "    Scatter(name=\"Average Error\", line=dash,\n",
    "            x = plotdata.BatchSize, y = avgError)]\n",
    "|> Chart.Plot\n",
    "|> Chart.WithLayout\n",
    "       (Layout\n",
    "            (title = \"Minibatch run\", xaxis = Xaxis(title = \"Minibatch number\"),\n",
    "             yaxis = Yaxis(title = \"Cost\")))\n",
    "|> Chart.WithHeight 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run evaluation / Testing\n",
    "\n",
    "Wherein we generate a new dataset and see how good a job the model we just trained does in separating the differenct categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open System.Collections.Generic\n",
    "\n",
    "/// Convert dictionary to Variable -> Value map for CNTK\n",
    "/// Ported from https://github.com/Microsoft/CNTK/blob/master/bindings/csharp/CNTKLibraryManagedDll/Helper.cs\n",
    "/// <remarks> CNTK Helper function </remarks>\n",
    "let AsUnorderedMapVariableValue (source: IDictionary<Variable,Value>) =\n",
    "    let inputVector = new UnorderedMapVariableValuePtr()\n",
    "    for pair in source do inputVector.Add(pair.Key, pair.Value)\n",
    "    inputVector\n",
    "\n",
    "let testMinibatchSize = 25\n",
    "let x_test,y_test = generateRandomDataSample testMinibatchSize featureCount labelCount\n",
    "let testBatch = \n",
    "    [ (featureVariable, matrixToBatch x_test)\n",
    "      (labelVariable, matrixToBatch y_test) ] \n",
    "    |> dict\n",
    "    |> AsUnorderedMapVariableValue\n",
    "    \n",
    "trainer.TestMinibatch(testBatch, device)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking prediction / evaluation    \n",
    "\n",
    "Wherein we go a bit deeper on how our model behaves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">It is important to explicitly use a _System.Generic.Collections.Dictionary_ object as a data map for the evaluation target; F#'s own <b>dict</b> (Microsoft.FSharp.Core.ExtraTopLevelOperators) is read only, resulting in some misleading errors:\n",
    "\n",
    "<blockquote>\n",
    "Expression evaluation failed: Values for 1 required arguments 'Input('test_output', [2], [*, #])', that the requested output(s) 'Input('test_output', [2], [*, #])' depend on, have not been provided.\n",
    "</blockquote>\n",
    "or \n",
    "<blockquote>Expression evaluation failed: This value cannot be mutated\n",
    "NotSupportedExceptionThis value cannot be mutated</blockquote>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "/// Create System.Collections.Generic.Dictionary<Variable,Value>\n",
    "/// from corresponding tuple seq. Useful when a CNTK Data Map needs\n",
    "/// to be mutable, fot instance when it's going to be holding data\n",
    "/// generated from our model.\n",
    "/// <remarks> CNTK Helper function </remarks>\n",
    "let dataMap (source: seq<Variable*Value>) = \n",
    "    let result = Dictionary<Variable,Value>()\n",
    "    for key,value in source do result.Add(key,value)\n",
    "    result\n",
    "\n",
    "/// A Function.Evaluate friendly one-hot -> boolean parser function\n",
    "let parseOneHotPairs (source: IList<IList<float32>>) = \n",
    "    source \n",
    "    |> Seq.map Seq.head \n",
    "    |> Seq.map (float>>System.Math.Round>>float32)\n",
    "    |> Array.ofSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing results and per sample comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let out = CNTKLib.Softmax(new Variable(z))\n",
    "let outputDataMap = [(out.Output, null)] |> dataMap\n",
    "let inputDataMap = [(featureVariable, matrixToBatch x_test)] |> dict\n",
    "\n",
    "out.Evaluate(inputDataMap, outputDataMap, device)            \n",
    "\n",
    "let result = outputDataMap.[out.Output].GetDenseData<float32>(out.Output)\n",
    "\n",
    "let labelsBinary = y_test.[*,0] |> Array.ofSeq    \n",
    "let predictedBinary = result |> parseOneHotPairs \n",
    "    \n",
    "labelsBinary |> Array.take 10 |> printfn \"Label    : %A ...\"    \n",
    "predictedBinary |> Array.take 10 |> printfn \"Predicted: %A ...\"\n",
    "\n",
    "(labelsBinary, predictedBinary) \n",
    "||> Array.zip\n",
    "|>  Array.countBy (fun (label,predicted) -> label = predicted)\n",
    "|>  printfn \"Success  : %A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// A helper function to extract data from parameter nodes.\n",
    "/// You can use this to see a layer's weights.\n",
    "/// <remarks> CNTK Helper function </remarks>/\n",
    "let paramData<'T> (p: CNTK.Parameter) =\n",
    "    let arrayView = p.Value()\n",
    "    let value = new Value(arrayView)\n",
    "    value.GetDenseData<'T>(p)\n",
    "\n",
    "(* The index we created along with the linear layer function\n",
    "   finaly comes useful!\n",
    "   \n",
    "   Seq.head is because the result of Value.GetDense is always 2D\n",
    "*)\n",
    "let weightMatrix = \n",
    "    index.[\"Weights\"] \n",
    "    |> paramData<float32>\n",
    "    |> Seq.head\n",
    "    |> Seq.chunkBySize featureCount\n",
    "    |> Array.ofSeq\n",
    "   \n",
    "let biasVector = \n",
    "    index.[\"Bias\"] \n",
    "    |> paramData<float32>\n",
    "    |> Seq.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that without hidden layers a neural network is only capable of linear separation, we can plot the exact line of separation using the the two points where it intersects with the chart's axes, i.e. where either x = 0 or y = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let separator_x = [0.f; biasVector.[1]/weightMatrix.[0].[0]]\n",
    "let separator_y = [biasVector.[0]/weightMatrix.[0].[1]; 0.f]\n",
    "\n",
    "separator_x, separator_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ Scatter(x = x.[*,0], y = x.[*,1], \n",
    "          mode = \"markers\", \n",
    "          marker = Marker(size=10, color=colors))\n",
    "  Scatter(x = separator_x, y = separator_y, \n",
    "          mode = \"lines\",          \n",
    "          line = Line(color=\"Green\", width=3)) ]\n",
    "|> Chart.Plot\n",
    "|> Chart.WithLayout (\n",
    "        Layout( xaxis=Xaxis(title=\"Tumor size (in cm)\"), \n",
    "                yaxis=Yaxis(title=\"Age (scaled)\")))\n",
    "|> Chart.WithHeight 400\n",
    "|> Chart.WithWidth 600        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction heatmap & revisiting evaluation\n",
    "\n",
    "We have now pretty much covered the original tutorial. But! Why not refactor evaluation a bit, and show another cool way to visualise how the trained model works by using a heatmap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let batchFromSeq (dim:int) (source : float seq) =\n",
    "    CNTK.Value.CreateBatch(shape [dim], source |> Seq.map (float32), device)\n",
    "\n",
    "let evaluateWithSoftmax (model : Function) (source : float seq seq) =\n",
    "    let inputDim = source |> Seq.head |> Seq.length\n",
    "    let inputData = source |> Seq.collect id |> batchFromSeq inputDim\n",
    "    let out = CNTKLib.Softmax(new Variable(model))\n",
    "    \n",
    "    let inputDataMap = [out.Arguments.[0], inputData] |> dict\n",
    "    let outputDataMap = [(out.Output, null)] |> dataMap\n",
    "    \n",
    "    out.Evaluate(inputDataMap, outputDataMap, device)            \n",
    "\n",
    "    outputDataMap\n",
    "        .[out.Output]\n",
    "        .GetDenseData<float32>(out.Output)\n",
    "    |> Seq.map Seq.head\n",
    "\n",
    "let predictedLabelGrid (range : float[]) =\n",
    "    seq [for x in range do for y in range do yield seq [x;y] ]\n",
    "    |> evaluateWithSoftmax z\n",
    "    |> Array.ofSeq\n",
    "    |> Array.chunkBySize range.Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let colorScale =\n",
    "    (* Scale from https://fslab.org/XPlot/chart/plotly-heatmaps.html\n",
    "     * Default scales available: 'Greys' | 'Greens' | 'Bluered' | 'Hot' | 'Picnic' | 'Portland' | 'Jet' | 'RdBu' | 'Blackbody' | 'Earth' | 'Electric' | 'YIOrRd' | 'YIGnBu'\n",
    "     *)\n",
    "    [\n",
    "        [box 0.0; box \"rgb(165,0,38)\"]\n",
    "        [0.1111111111111111; \"rgb(215,48,39)\"]\n",
    "        [0.2222222222222222; \"rgb(244,109,67)\"]\n",
    "        [0.3333333333333333; \"rgb(253,174,97)\"]\n",
    "        [0.4444444444444444; \"rgb(254,224,144)\"]\n",
    "        [0.5555555555555556; \"rgb(224,243,248)\"]\n",
    "        [0.6666666666666666; \"rgb(171,217,233)\"]\n",
    "        [0.7777777777777778; \"rgb(116,173,209)\"]\n",
    "        [0.8888888888888888; \"rgb(69,117,180)\"]\n",
    "        [1.0; \"rgb(49,54,149)\"]\n",
    "    ]\n",
    "\n",
    "Heatmap(z = (predictedLabelGrid [|1. .. 0.1 .. 10.|]), colorscale = colorScale)\n",
    "|> Chart.Plot\n",
    "|> Chart.WithLayout (\n",
    "        Layout( xaxis=Xaxis(title=\"Tumor size (in cm)\"), \n",
    "                yaxis=Yaxis(title=\"Age (scaled)\")))\n",
    "|> Chart.WithWidth 700\n",
    "|> Chart.WithHeight 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we keep adding hidden layers this heatmap is only going to get more interesting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "F#",
   "language": "fsharp",
   "name": "ifsharp"
  },
  "language": "fsharp",
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".fs",
   "mimetype": "text/x-fsharp",
   "name": "fsharp",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "4.3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
