
 {
 "cells": [{
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "(*** hide ***)"
        ]
        
    }, {
        "cell_type": "code",
        "metadata": {},
        "source": [
            "\n#I \"../../bin/net45\"\n#load \"Deedle.fsx\"\n#I \"../../packages/MathNet.Numerics/lib/net40\"\n#load \"../../packages/FSharp.Charting/lib/net45/FSharp.Charting.fsx\"\nopen System\nopen FSharp.Data\nopen Deedle\nopen FSharp.Charting\n\nlet root = __SOURCE_DIRECTORY__ + \"/data/\"\n\n"
        ]
        ,"execution_count": null,"outputs": []
    }, {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "(**\nWorking with series and time series data in F#\n==============================================\n\nIn this section, we look at F# data frame library features that are useful when working\nwith time series data or, more generally, any ordered series. Although we mainly look at\noperations on the `Series` type, many of the operations can be applied to data frame `Frame`\ncontaining multiple series. Furthermore, data frame provides an elegant way for aligning and\njoining series. \n\nYou can also get this page as an [F# script file](https://github.com/fslaborg/Deedle/blob/master/docs/content/series.fsx)\nfrom GitHub and run the samples interactively.\n\nGenerating input data\n---------------------\n\nFor the purpose of this tutorial, we'll need some input data. For simplicitly, we use the\nfollowing function which generates random prices using the geometric Brownian motion.\nThe code is adapted from the [financial tutorial on Try F#](http://www.tryfsharp.org/Learn/financial-computing#simulating-and-analyzing).\n\n*)"
        ]
        
    }, {
        "cell_type": "code",
        "metadata": {},
        "source": [
            "\n\n// Use Math.NET for probability distributions\n#r \"MathNet.Numerics.dll\"\nopen MathNet.Numerics.Distributions\n\n/// Generates price using geometric Brownian motion\n///  - 'seed' specifies the seed for random number generator\n///  - 'drift' and 'volatility' set properties of the price movement\n///  - 'initial' and 'start' specify the initial price and date\n///  - 'span' specifies time span between individual observations\n///  - 'count' is the number of required values to generate\nlet randomPrice seed drift volatility initial start span count = \n"
        ]
        ,"execution_count": null,"outputs": []
    }, {
        "cell_type": "code",
        "metadata": {},
        "source": [
            "(*[omit:(Implementation omitted)]*) \n  let dist = Normal(0.0, 1.0, RandomSource=Random(seed))  \n  let dt = (span:TimeSpan).TotalDays / 250.0\n  let driftExp = (drift - 0.5 * pown volatility 2) * dt\n  let randExp = volatility * (sqrt dt)\n  ((start:DateTimeOffset), initial) |> Seq.unfold (fun (dt, price) ->\n    let price = price * exp (driftExp + randExp * dist.Sample()) \n    Some((dt, price), (dt + span, price))) |> Seq.take count\n\n// 12:00 AM today, in current time zone\nlet today = DateTimeOffset(DateTime.Today)\nlet stock1 = randomPrice 1 0.1 3.0 20.0 today \nlet stock2 = randomPrice 2 0.2 1.5 22.0 today\n(**\nThe implementation of the function is not particularly important for the purpose of this\npage, but you can find it in the [script file with full source](https://github.com/fslaborg/Deedle/blob/master/docs/content/series.fsx).\nOnce we have the function, we define a date `today` (representing today's midnight) and\ntwo helper functions that set basic properties for the `randomPrice` function. \n\nTo get random prices, we now only need to call `stock1` or `stock2` with `TimeSpan` and \nthe required number of prices:\n*)\n(*** define-output: stocks ***)\nChart.Combine\n  [ stock1 (TimeSpan(0, 1, 0)) 1000 |> Chart.FastLine\n    stock2 (TimeSpan(0, 1, 0)) 1000 |> Chart.FastLine ]\n(**\nThe above snippet generates 1k of prices in one minute intervals and plots them using the\n[F# Charting library](https://github.com/fsharp/FSharp.Charting). When you run the code\nand tweak the chart look, you should see something like this:\n*)\n\n(*** include-it: stocks ***)\n\n(**\n<a name=\"alignment\"></a>\nData alignment and zipping\n--------------------------\n\nOne of the key features of the data frame library for working with time series data is \n_automatic alignment_ based on the keys. When we have multiple time series with date \nas the key (here, we use `DateTimeOffset`, but any type of date will do), we can combine\nmultiple series and align them automatically to specified date keys.\n\nTo demonstrate this feature, we generate random prices in 60 minute, 30 minute and \n65 minute intervals:\n*)\n\nlet s1 = stock1 (TimeSpan(1, 0, 0)) 6 |> series\n// [fsi:val s1 : Series<DateTimeOffset,float> =]\n// [fsi:  series [ 12:00:00 AM => 20.76; 1:00:00 AM => 21.11; 2:00:00 AM => 22.51 ]\n// [fsi:            3:00:00 AM => 23.88; 4:00:00 AM => 23.23; 5:00:00 AM => 22.68 ] ]\n\nlet s2 =stock2 (TimeSpan(0, 30, 0)) 12 |> series\n// [fsi:val s2 : Series<DateTimeOffset,float> =]\n// [fsi:  series [ 12:00:00 AM => 21.61; 12:30:00 AM => 21.64; 1:00:00 AM => 21.86 ]\n// [fsi:            1:30:00 AM => 22.22;  2:00:00 AM => 22.35; 2:30:00 AM => 22.76 ]\n// [fsi:            3:00:00 AM => 22.68;  3:30:00 AM => 22.64; 4:00:00 AM => 22.90 ]\n// [fsi:            4:30:00 AM => 23.40;  5:00:00 AM => 23.33; 5:30:00 AM => 23.43] ]\n\nlet s3 = stock1 (TimeSpan(1, 5, 0)) 6 |> series\n// [fsi:val s3 : Series<DateTimeOffset,float> =]\n// [fsi:  series [ 12:00:00 AM => 21.37; 1:05:00 AM => 22.73; 2:10:00 AM => 22.08 ]\n// [fsi:            3:15:00 AM => 23.92; 4:20:00 AM => 22.72; 5:25:00 AM => 22.79 ]\n\n(**\n### Zipping time series \n\nLet's first look at operations that are available on the `Series<K, V>` type. A series\nexposes `Zip` operation that can combine multiple series into a single series of pairs.\nThis is not as convenient as working with data frames (which we'll see later), but it \nis useful if you only need to work with one or two columns without missing values:\n\n*)\n// Match values from right series to keys of the left one\n// (this creates series with no missing values)\ns1.Zip(s2, JoinKind.Left)\n// [fsi:val it : Series<DateTimeOffset,float opt * float opt>]\n// [fsi:  12:00:00 AM -> (21.32, 21.61) ]\n// [fsi:   1:00:00 AM -> (22.62, 21.86) ]\n// [fsi:   2:00:00 AM -> (22.00, 22.35)  ]\n// [fsi:  (...)]\n\n// Match values from the left series to keys of the right one\n// (right has higher resolution, so half of left values are missing)\ns1.Zip(s2, JoinKind.Right)\n// [fsi:val it : Series<DateTimeOffset,float opt * float opt>]\n// [fsi:  12:00:00 AM -> (21.32,     21.61) ]\n// [fsi:  12:30:00 AM -> (<missing>, 21.64)  ]      \n// [fsi:   1:00:00 AM -> (22.62,     21.86) ]\n// [fsi:  (...)]\n\n// Use left series key and find the nearest previous\n// (smaller) value from the right series\ns1.Zip(s2, JoinKind.Left, Lookup.ExactOrSmaller)\n// [fsi:val it : Series<DateTimeOffset,float opt * float opt>]\n// [fsi:  12:00:00 AM -04:00 -> (21.32, 21.61) ]\n// [fsi:   1:00:00 AM -04:00 -> (22.62, 21.86) ]\n// [fsi:   2:00:00 AM -04:00 -> (22.00, 22.35)  ]\n// [fsi:  (...)]\n\n(**\nUsing `Zip` on series is somewhat complicated. The result is a series of tuples, but each \ncomponent of the tuple may be missing. To represent this, the library uses the `T opt` type\n(a type alias for `OptionalValue<T>`). This is not necessary when we use data frame to \nwork with multiple columns.\n\n### Joining data frames\n\nWhen we store data in data frames, we do not need to use tuples to represent combined values.\nInstead, we can simply use data frame with multiple columns. To see how this works, let's first\ncreate three data frames containing the three series from the previous section:\n*)\n\n// Contains value for each hour\nlet f1 = Frame.ofColumns [\"S1\" => s1]\n// Contains value every 30 minutes\nlet f2 = Frame.ofColumns [\"S2\" => s2]\n// Contains values with 65 minute offsets\nlet f3 = Frame.ofColumns [\"S3\" => s3]\n\n(**\nSimilarly to `Series<K, V>`, the type `Frame<R, C>` has an instance method `Join` that can be\nused for joining (for unordered) or aligning (for ordered) data. The same operation is also\nexposed as `Frame.join` and `Frame.joinAlign` functions, but it is usually more convenient to use \nthe member syntax in this case:\n*)\n\n// Union keys from both frames and align corresponding values\nf1.Join(f2, JoinKind.Outer)\n// [fsi:val it : Frame<DateTimeOffset,string> =]\n// [fsi:                 S1        S2               ]\n// [fsi:  12:00:00 AM -> 21.32     21.61 ]\n// [fsi:  12:30:00 AM -> <missing> 21.64 ]\n// [fsi:   1:00:00 AM -> 22.62     21.86 ]\n// [fsi:  (...)]\n\n// Take only keys where both frames contain all values\n// (We get only a single row, because 'f3' is off by 5 minutes)\nf2.Join(f3, JoinKind.Inner)\n// [fsi:val it : Frame<DateTimeOffset,string> =]\n// [fsi:                 S2      S3               ]\n// [fsi:  12:00:00 AM -> 21.61   21.37 ]\n\n// Take keys from the left frame and find corresponding values\n// from the right frame, or value for a nearest smaller date\n// ($21.37 is repeated for all values between 12:00 and 1:05)\nf2.Join(f3, JoinKind.Left, Lookup.ExactOrSmaller)\n// [fsi:val it : Frame<DateTimeOffset,string> =]\n// [fsi:                 S2      S3               ]\n// [fsi:  12:00:00 AM -> 21.61   21.37 ]\n// [fsi:  12:30:00 AM -> 21.64   21.37 ]\n// [fsi:   1:00:00 AM -> 21.86   21.37 ]\n// [fsi:   1:30:00 AM -> 22.22   22.73 ]\n// [fsi:  (...)]\n\n// If we perform left join as previously, but specify exact \n// matching, then most of the values are missing\nf2.Join(f3, JoinKind.Left, Lookup.Exact)\n// [fsi:val it : Frame<DateTimeOffset,string> =]\n// [fsi:                 S2      S3               ]\n// [fsi:  12:00:00 AM -> 21.61   21.37]\n// [fsi:  12:30:00 AM -> 21.64   <missing>        ]\n// [fsi:   1:00:00 AM -> 21.86   <missing>        ]\n// [fsi:  (...)]\n\n// Equivalent to line 2, using function syntax \nFrame.join JoinKind.Outer f1 f2\n\n// Equivalent to line 20, using function syntax\nFrame.joinAlign JoinKind.Left Lookup.ExactOrSmaller f1 f2\n\n(**\nThe automatic alignment is extremely useful when you have multiple data series with different\noffsets between individual observations. You can choose your set of keys (dates) and then easily\nalign other data to match the keys. Another alternative to using `Join` explicitly is to create\na new frame with just keys that you are interested in (using `Frame.ofRowKeys`) and then use\nthe `AddSeries` member (or the `df?New <- s` syntax) to add series. This will automatically left\njoin the new series to match the current row keys.\n\nWhen aligning data, you may or may not want to create data frame with missing values. If your\nobservations do not happen at exact time, then using `Lookup.ExactOrSmaller` or `Lookup.ExactOrGreater`\nis a great way to avoid mismatch. \n\nIf you have observations that happen e.g. at two times faster rate (one series is hourly and \nanother is half-hourly), then you can create data frame with missing values using `Lookup.Exact` \n(the default value) and then handle missing values explicitly (as [discussed here](frame.html#missing)).\n\n\n<a name=\"windowing\"></a>\nWindowing, chunking and pairwise\n--------------------------------\n\nWindowing and chunking are two operations on ordered series that allow aggregating\nthe values of series into groups. Both of these operations work on consecutive elements,\nwhich contrast with [grouping](tutorial.html#grouping) that does not use order.\n\n### Sliding windows\n\nSliding window creates windows of certain size (or certain condition). The window\n\"slides\" over the input series and provides a view on a part of the series. The\nkey thing is that a single element will typically appear in multiple windows.\n*)\n\n// Create input series with 6 observations\nlet lf = stock1 (TimeSpan(0, 1, 0)) 6 |> series\n\n// Create series of series representing individual windows\nlf |> Series.window 4\n// Aggregate each window using 'Stats.mean'\nlf |> Series.windowInto 4 Stats.mean\n// Get first value in each window\nlf |> Series.windowInto 4 Series.firstValue\n\n(**\nThe functions used above create window of size 4 that moves from the left to right.\nGiven input `[1,2,3,4,5,6]` the this produces the following three windows:\n`[1,2,3,4]`, `[2,3,4,5]` and `[3,4,5,6]`. By default, the `Series.window` function \nautomatically chooses the key of the last element of the window as the key for \nthe whole window (we'll see how to change this soon):\n\n*)\n// Calculate means for sliding windows\nlet lfm1 = lf |> Series.windowInto 4 Stats.mean\n// Construct dataframe to show aligned results\nFrame.ofColumns [ \"Orig\" => lf; \"Means\" => lfm1 ]\n// [fsi:val it : Frame<DateTimeOffset,string> =]\n// [fsi:                 Means      Orig        ]     \n// [fsi:  12:00:00 AM -> <missing>  20.16]\n// [fsi:  12:01:00 AM -> <missing>  20.32]\n// [fsi:  12:02:00 AM -> <missing>  20.25]\n// [fsi:  12:03:00 AM -> 20.30      20.45]\n// [fsi:  12:04:00 AM -> 20.34      20.32]\n// [fsi:  12:05:00 AM -> 20.34      20.33]\n\n(**\nWhat if we want to avoid creating `<missing>` values? One approach is to \nspecify that we want to generate windows of smaller sizes at the beginning \nor at the end of the beginning. This way, we get _incomplete_ windows that look as \n`[1]`, `[1,2]`, `[1,2,3]` followed by the three _complete_ windows shown above:\n*)\nlet lfm2 = \n  // Create sliding windows with incomplete windows at the beginning\n  lf |> Series.windowSizeInto (4, Boundary.AtBeginning) (fun ds ->\n    Stats.mean ds.Data)\n\nFrame.ofColumns [ \"Orig\" => lf; \"Means\" => lfm2 ]\n// [fsi:val it : Frame<DateTimeOffset,string> =]\n// [fsi:                 Means  Orig        ]     \n// [fsi:  12:00:00 AM -> 20.16  20.16]\n// [fsi:  12:01:00 AM -> 20.24  20.32]\n// [fsi:  12:02:00 AM -> 20.24  20.25]\n// [fsi:  12:03:00 AM -> 20.30  20.45]\n// [fsi:  12:04:00 AM -> 20.34  20.32]\n// [fsi:  12:05:00 AM -> 20.34  20.33]\n\n(**\nAs you can see, the values in the first column are equal, because the first\n`Mean` value is just the average of singleton series.\n\nWhen you specify `Boundary.AtBeginning` (this example) or `Boundary.Skip` \n(default value used in the previous example), the function uses the last key\nof the window as the key of the aggregated value. When you specify \n`Boundary.AtEnding`, the last key is used, so the values can be nicely \naligned with original values. When you want to specify custom key selector,\nyou can use a more general function `Series.aggregate`. \n\nIn the previous sample, the code that performs aggregation is no longer\njust a simple function like `Stats.mean`, but a lambda that takes `ds`,\nwhich is of type `DataSegment<T>`. This type informs us whether the window\nis complete or not. For example:\n*)\n\n// Simple series with characters\nlet st = Series.ofValues [ 'a' .. 'e' ]\nst |> Series.windowSizeInto (3, Boundary.AtEnding) (function\n  | DataSegment.Complete(ser) -> \n      // Return complete windows as uppercase strings\n      String(ser |> Series.values |> Array.ofSeq).ToUpper()\n  | DataSegment.Incomplete(ser) -> \n      // Return incomplete windows as padded lowercase strings\n      String(ser |> Series.values |> Array.ofSeq).PadRight(3, '-') )  \n// [fsi:val it : Series<int,string> =]\n// [fsi:  0 -> ABC ]\n// [fsi:  1 -> BCD ]\n// [fsi:  2 -> CDE ]\n// [fsi:  3 -> de- ]\n// [fsi:  4 -> e-- ]\n\n(**\n### Window size conditions\n\nThe previous examples generated windows of fixed size. However, there are two other\noptions for specifying when a window ends. \n\n - The first option is to specify the maximal\n   _distance_ between the first and the last key\n - The second option is to specify a function that is called with the first\n   and the last key; a window ends when the function returns false.\n\nThe two functions are `Series.windowDist` and `Series.windowWhile` (together\nwith versions suffixed with `Into` that call a provided function to aggregate\neach window):\n*)\n// Generate prices for each hour over 30 days\nlet hourly = stock1 (TimeSpan(1, 0, 0)) (30*24) |> series\n\n// Generate windows of size 1 day (if the source was\n// irregular, windows would have varying size)\nhourly |> Series.windowDist (TimeSpan(24, 0, 0))\n\n// Generate windows such that date in each window is the same\n// (windows start every hour and end at the end of the day)\nhourly |> Series.windowWhile (fun d1 d2 -> d1.Date = d2.Date)\n\n(**\n### Chunking series\n\nChunking is similar to windowing, but it creates non-overlapping chunks, \nrather than (overlapping) sliding windows. The size of chunk can be specified\nin the same three ways as for sliding windows (fixed size, distance on keys\nand condition):\n*)\n\n// Generate per-second observations over 10 minutes\nlet hf = stock1 (TimeSpan(0, 0, 1)) 600 |> series\n\n// Create 10 second chunks with (possible) incomplete\n// chunk of smaller size at the end.\nhf |> Series.chunkSize (10, Boundary.AtEnding) \n\n// Create 10 second chunks using time span and get\n// the first observation for each chunk (downsample)\nhf |> Series.chunkDistInto (TimeSpan(0, 0, 10)) Series.firstValue\n\n// Create chunks where hh:mm component is the same\n// (containing observations for all seconds in the minute)\nhf |> Series.chunkWhile (fun k1 k2 -> \n  (k1.Hour, k1.Minute) = (k2.Hour, k2.Minute))\n\n(**\nThe above examples use various chunking functions in a very similar way, mainly\nbecause the randomly generated input is very uniform. However, they all behave\ndifferently for inputs with non-uniform keys. \n\nUsing `chunkSize` means that the chunks have the same size, but may correspond\nto time series of different time spans. Using `chunkDist` guarantees that there\nis a maximal time span over each chunk, but it does not guarantee when a chunk\nstarts. That is something which can be achieved using `chunkWhile`.\n\nFinally, all of the aggregations discussed so far are just special cases of\n`Series.aggregate` which takes a discriminated union that specifies the kind\nof aggregation ([see API reference](reference/fsharp-dataframe-aggregation-1.html)).\nHowever, in practice it is more convenient to use the helpers presented here -\nin some rare cases, you might need to use `Series.aggregate` as it provides\na few other options.\n\n### Pairwise \n\nA special form of windowing is building a series of pairs containing a current\nand previous value from the input series (in other words, the key for each pair\nis the key of the later element). For example:\n*)\n\n// Create a series of pairs from earlier 'hf' input\nhf |> Series.pairwise \n\n// Calculate differences between the current and previous values\nhf |> Series.pairwiseWith (fun k (v1, v2) -> v2 - v1)\n\n(** \nThe `pairwise` operation always returns a series that has no value for\nthe first key in the input series. If you want more complex behavior, you\nwill usually need to replace `pairwise` with `window`. For example, you might\nwant to get a series that contains the first value as the first element, \nfollowed by differences. This has the nice property that summing rows,\nstarting from the first one gives you the current price:\n*)\n// Sliding window with incomplete segment at the beginning \nhf |> Series.windowSizeInto (2, Boundary.AtBeginning) (function\n  // Return the first value for the first segment\n  | DataSegment.Incomplete s -> s.GetAt(0)\n  // Calculate difference for all later segments\n  | DataSegment.Complete s -> s.GetAt(1) - s.GetAt(0))\n\n(**\n\n<a name=\"sampling\"></a>\nSampling and resampling time series\n-----------------------------------\n\nGiven a time series with high-frequency prices, sampling or resampling makes \nit possible to get time series with representative values at lower frequency.\nThe library uses the following terminology:\n\n - **Lookup** means that we find values at specified key; if a key is not\n   available, we can look for value associated with the nearest smaller or \n   the nearest greater key.\n\n - **Resampling** means that we aggregate values values into chunks based\n   on a specified collection of keys (e.g. explicitly provided times), or \n   based on some relation between keys (e.g. date times having the same date).\n\n - **Uniform resampling** is similar to resampling, but we specify keys by\n   providing functions that generate a uniform sequence of keys (e.g. days),\n   the operation also fills value for days that have no corresponding \n   observations in the input sequence.\n\nFinally, the library also provides a few helper functions that are specifically\ndesinged for series with keys of types `DateTime` and `DateTimeOffset`.\n\n### Lookup\n\nGiven a series `hf`, you can get a value at a specified key using `hf.Get(key)`\nor using `hf |> Series.get key`. However, it is also possible to find values\nfor larger number of keys at once. The instance member for doing this\nis `hf.GetItems(..)`. Moreover, both `Get` and `GetItems` take an optional\nparameter that specifies the behavior when the exact key is not found.\n\nUsing the function syntax, you can use `Series.getAll` for exact key \nlookup and `Series.lookupAll` when you want more flexible lookup:\n*)\n// Generate a bit less than 24 hours of data with 13.7sec offsets\nlet mf = stock1 (TimeSpan.FromSeconds(13.7)) 6300 |> series\n// Generate keys for all minutes in 24 hours\nlet keys = [ for m in 0.0 .. 24.0*60.0-1.0 -> today.AddMinutes(m) ]\n\n// Find value for a given key, or nearest greater key with value\nmf |> Series.lookupAll keys Lookup.ExactOrGreater\n// [fsi:val it : Series<DateTimeOffset,float> =]\n// [fsi:  12:00:00 AM -> 20.07 ]\n// [fsi:  12:01:00 AM -> 19.98 ]\n// [fsi:  ...         -> ...   ]\n// [fsi:  11:58:00 PM -> 19.03 ]\n// [fsi:  11:59:00 PM -> <missing>        ]\n\n// Find value for nearest smaller key\n// (This returns value for 11:59:00 PM as well)\nmf |> Series.lookupAll keys Lookup.ExactOrSmaller\n\n// Find values for exact key \n// (This only works for the first key)\nmf |> Series.lookupAll keys Lookup.Exact\n\n(**\nLookup operations only return one value for each key, so they are useful for\nquick sampling of large (or high-frequency) data. When we want to calculate\na new value based on multiple values, we need to use resampling.\n\n### Resampling\n\nSeries supports two kinds of resamplings. The first kind is similar to lookup\nin that we have to explicitly specify keys. The difference is that resampling\ndoes not find just the nearest key, but all smaller or greater keys. For example:\n*)\n\n// For each key, collect values for greater keys until the \n// next one (chunk for 11:59:00 PM is empty)\nmf |> Series.resample keys Direction.Forward\n\n// For each key, collect values for smaller keys until the \n// previous one (the first chunk will be singleton series)\nmf |> Series.resample keys Direction.Backward\n\n// Aggregate each chunk of preceding values using mean\nmf |> Series.resampleInto keys Direction.Backward \n  (fun k s -> Stats.mean s)\n\n// Resampling is also available via the member syntax\nmf.Resample(keys, Direction.Forward)\n(**\n\nThe second kind of resampling is based on a projection from existing keys in \nthe series. The operation then collects chunks such that the projection returns\nequal keys. This is very similar to `Series.groupBy`, but resampling assumes \nthat the projection preserves the ordering of the keys, and so it only aggregates\nconsequent keys.\n\nThe typical scenario is when you have time series with date time information\n(here `DateTimeOffset`) and want to get information for each day (we use \n`DateTime` with empty time to represent dates):\n*)\n\n// Generate 2.5 months of data in 1.7 hour offsets\nlet ds = stock1 (TimeSpan.FromHours(1.7)) 1000 |> series\n\n// Sample by day (of type 'DateTime')\nds |> Series.resampleEquiv (fun d -> d.Date)\n\n// Sample by day (of type 'DateTime')\nds.ResampleEquivalence(fun d -> d.Date)\n(**\nThe same operation can be easily implemented using `Series.chunkWhile`, but as\nit is often used in the context of sampling, it is included in the library as a\nprimitive. Moreover, we'll see that it is closely related to uniform resampling.\n\nNote that the resulting series has different type of keys than the source. The\nsource has keys `DateTimeOffset` (representing date with time) while the resulting\nkeys are of the type returned by the projection (here, `DateTime` representing just\ndates).\n\n### Uniform resampling\n\nIn the previous section, we looked at `resampleEquiv`, which is useful if you want\nto sample time series by keys with \"lower resolution\" - for example, sample date time\nobservations by date. However, the function discussed in the previous section only\ngenerates values for which there are keys in the input sequence - if there is no\nobservation for an entire day, then the day will not be included in the result.\n\nIf you want to create sampling that assigns value to each key in the range specified\nby the input sequence, then you can use _uniform resampling_.\n\nThe idea is that uniform resampling applies the key projection to the smallest and\ngreatest key of the input (e.g. gets date of the first and last observation) and then\nit generates all keys in the projected space (e.g. all dates). Then it picks the\nbest value for each of the generated key.\n*)\n\n// Create input data with non-uniformly distributed keys\n// (1 value for 10/3, three for 10/4 and two for 10/6)\nlet days =\n  [ \"10/3/2013 12:00:00\"; \"10/4/2013 15:00:00\" \n    \"10/4/2013 18:00:00\"; \"10/4/2013 19:00:00\"\n    \"10/6/2013 15:00:00\"; \"10/6/2013 21:00:00\" ]\nlet nu = \n  stock1 (TimeSpan(24,0,0)) 10 |> series\n  |> Series.indexWith days |> Series.mapKeys DateTimeOffset.Parse\n\n// Generate uniform resampling based on dates. Fill\n// missing chunks with nearest smaller observations.\nlet sampled =\n  nu |> Series.resampleUniform Lookup.ExactOrSmaller \n    (fun dt -> dt.Date) (fun dt -> dt.AddDays(1.0))\n\n// Same thing using the C#-friendly member syntax\n// (Lookup.ExactOrSmaller is the default value)\nnu.ResampleUniform((fun dt -> dt.Date), (fun dt -> dt.AddDays(1.0)))\n\n// Turn into frame with multiple columns for each day\n// (to format the result in a readable way)\nsampled \n|> Series.mapValues Series.indexOrdinally\n|> Frame.ofRows\n// [fsi:val it : Frame<DateTime,int> =]\n// [fsi:             0      1          2                ]\n// [fsi:10/3/2013 -> 21.45  <missing>  <missing>        ]\n// [fsi:10/4/2013 -> 21.63  19.83      17.51]\n// [fsi:10/5/2013 -> 17.51  <missing>  <missing>        ]\n// [fsi:10/6/2013 -> 18.80  20.93      <missing>        ]\n\n(**\nTo perform the uniform resampling, we need to specify how to project (resampled) keys\nfrom original keys (we return the `Date`), how to calculate the next key (add 1 day)\nand how to fill missing values.\n\nAfter performing the resampling, we turn the data into a data frame, so that we can \nnicely see the results. The individual chunks have the actual observation times as keys,\nso we replace those with just integers (using `Series.indexOrdinal`). The result contains\na simple ordered row of observations for each day.\n\nThe important thing is that there is an observation for each day - even for for 10/5/2013\nwhich does not have any corresponding observations in the input. We call the resampling\nfunction with `Lookup.ExactOrSmaller`, so the value 17.51 is picked from the last observation\nof the previous day (`Lookup.ExactOrGreater` would pick 18.80 and `Lookup.Exact` would give\nus an empty series for that date).\n\n### Sampling time series\n\nPerhaps the most common sampling operation that you might want to do is to sample time series\nby a specified `TimeSpan`. Although this can be easily done by using some of the functions above,\nthe library provides helper functions exactly for this purpose:\n\n*)\n// Generate 1k observations with 1.7 hour offsets\nlet pr = stock1 (TimeSpan.FromHours(1.7)) 1000 |> series\n\n// Sample at 2 hour intervals; 'Backward' specifies that\n// we collect all previous values into a chunk.\npr |> Series.sampleTime (TimeSpan(2, 0, 0)) Direction.Backward\n\n// Same thing using member syntax - 'Backward' is the dafult\npr.Sample(TimeSpan(2, 0, 0))\n\n// Get the most recent value, sampled at 2 hour intervals\npr |> Series.sampleTimeInto\n  (TimeSpan(2, 0, 0)) Direction.Backward Series.lastValue\n\n(**\n<a name=\"stats\"></a>\nCalculations and statistics\n---------------------------\n\nIn the final section of this tutorial, we look at writing some calculations over time series. Many of the\nfunctions demonstrated here can be also used on unordered data frames and series.\n\n### Shifting and differences\n\nFirst of all, let's look at functions that we need when we need to compare subsequent values in\nthe series. We already demonstrated how to do this using `Series.pairwise`. In many cases,\nthe same thing can be done using an operation that operates over the entire series.\n\nThe two useful functions here are:\n\n - `Series.diff` calcualtes the difference between current and n-_th_  previous element\n - `Series.shift` shifts the values of a series by a specified offset\n\nThe following snippet illustrates how both functions work:\n*)\n// Generate sample data with 1.7 hour offsets\nlet sample = stock1 (TimeSpan.FromHours(1.7)) 6 |> series\n\n// Calculates: new[i] = s[i] - s[i-1]\nlet diff1 = sample |> Series.diff 1\n// Diff in the opposite direction\nlet diffM1 = sample |> Series.diff -1\n\n// Shift series values by 1\nlet shift1 = sample |> Series.shift 1\n\n// Align all results in a frame to see the results\nlet df = \n  [ \"Shift +1\" => shift1 \n    \"Diff +1\" => diff1 \n    \"Diff\" => sample - shift1 \n    \"Orig\" => sample ] |> Frame.ofColumns \n// [fsi:val it : Frame<DateTimeOffset,string> =]\n// [fsi:                 Diff       Diff +1    Orig   Shift +1         ]\n// [fsi:  12:00:00 AM -> <missing>  <missing>  21.73  <missing>        ]\n// [fsi:   1:42:00 AM ->  1.73       1.73      23.47  21.73 ]\n// [fsi:   3:24:00 AM -> -0.83      -0.83      22.63  23.47 ]\n// [fsi:   5:06:00 AM ->  2.37       2.37      25.01  22.63 ]\n// [fsi:   6:48:00 AM -> -1.57      -1.57      23.43  25.01 ]\n// [fsi:   8:30:00 AM ->  0.09       0.09      23.52  23.43 ]\n\n(**\nIn the above snippet, we first calcluate difference using the `Series.diff` function.\nThen we also show how to do that using `Series.shift` and binary operator applied\nto two series (`sample - shift`). The following section provides more details. \nSo far, we also used the functional notation (e.g. `sample |> Series.diff 1`), but\nall operations can be called using the member syntax - very often, this gives you\na shorter syntax. This is also shown in the next few snippets.\n\n### Operators and functions\n\nTime series also supports a large number of standard F# functions such as `log` and `abs`.\nYou can also use standard numerical operators to apply some operation to all elements\nof the series. \n\nBecause series are indexed, we can also apply binary operators to two series. This \nautomatically aligns the series and then applies the operation on corresponding elements.\n\n*)\n\n// Subtract previous value from the current value\nsample - sample.Shift(1)\n\n// Calculate logarithm of such differences\nlog (sample - sample.Shift(1))\n\n// Calculate square of differences\nsample.Diff(1) ** 2.0\n\n// Calculate average of value and two immediate neighbors\n(sample.Shift(-1) + sample + sample.Shift(2)) / 3.0\n\n// Get absolute value of differences\nabs (sample - sample.Shift(1))\n\n// Get absolute value of distance from the mean\nabs (sample - (Stats.mean sample))\n\n(**\nThe time series library provides a large number of functions that can be applied in this\nway. These include trigonometric functions (`sin`, `cos`, ...), rounding functions\n(`round`, `floor`, `ceil`), exponentials and logarithms (`exp`, `log`, `log10`) and more.\nIn general, whenever there is a built-in numerical F# function that can be used on \nstandard types, the time series library should support it too.\n\nHowever, what can you do when you write a custom function to do some calculation and\nwant to apply it to all series elements? Let's have a look:\n*)\n\n// Truncate value to interval [-1.0, +1.0]\nlet adjust v = min 1.0 (max -1.0 v)\n\n// Apply adjustment to all function\nadjust $ sample.Diff(1)\n\n// The $ operator is a shorthand for\nsample.Diff(1) |> Series.mapValues adjust\n\n(**\nIn general, the best way to apply custom functions to all values in a series is to \nalign the series (using either `Series.join` or `Series.joinAlign`) into a single series\ncontaining tuples and then apply `Series.mapValues`. The library also provides the `$` operator\nthat simplifies the last step - `f $ s` applies the function `f` to all values of the series `s`.\n\n### Data frame operations\n\nFinally, many of the time series operations demonstrated above can be applied to entire\ndata frames as well. This is particularly useful if you have data frame that contains multiple\naligned time series of similar structure (for example, if you have multiple stock prices or \nopen-high-low-close values for a given stock). \n\nThe following snippet is a quick overview of what you can do:\n*)\n/// Multiply all numeric columns by a given constant\ndf * 0.65\n\n// Apply function to all columns in all series\nlet conv x = min x 20.0\ndf |> Frame.mapRowValues (fun os -> conv $ os.As<float>())\n   |> Frame.ofRows\n\n// Sum each column and divide results by a constant\nStats.sum df / 6.0\n// Divide sum by mean of each frame column\nStats.sum df / Stats.mean df\n"
        ]
        ,"execution_count": null,"outputs": []
    }],
 "metadata": {
  "kernelspec": {
   "display_name": "F#",
   "language": "fsharp",
   "name": "ifsharp"
  },
  "language": "fsharp",
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".fs",
   "mimetype": "text/x-fsharp",
   "name": "fsharp",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "4.3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
